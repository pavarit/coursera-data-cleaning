library(swirl)
swirl()
d1 <- Sys.Date()
class(d1)
unclass(d1)
d1
d2 <- as.Date("1969-01-01")
unclass(d2)
Sys.time()
t1 <- Sys.time()
t1
class(t1)
unclass(t1)
t2 <- as.POSIXlt(Sys.time())
class(t2)
t2
unclass(t2)
str(unclass(t2))
play()
?str
nxt()
t2$min
weekdays(d1)
months(t1)
quarters(t2)
t3 <- "October 17, 1986 08:24"
t4 <- strptime(t3, "%B %d, %Y %H:%M")
?strptime
t4
class(t4)
Sys.time > t1
Sys.time() > t1
Sys.time() - t1
difftime(Sys.time(, t1, units = "days"))
difftime(Sys.time(), t1, units = "days")
?gl
printmessage <- function(x) {}
printmessage <- function(x) {
if(x>0)
print("x grater 0")
else
print("x less 0")
}
printmessage(1)
?invisible
x <- printmessage(1)
x
printmessage <- function(x) {
if(x>0)
print("x grater 0")
else
print("x less 0")
invisible(x)
}
x <- printmessage(1)
x
library(datasets)
data(iris)
?data
?iris
iris
?tapply
tapply(iris$Sepal.Length, iris$Species)
tapply(iris$Sepal.Length, iris$Species, mean)
colMeans(iris)
apply(iris, 2,mean)
apply(iris, 1,mean)
apply(iris[, 1:4], 1,mean)
apply(iris[, 1:4], 2,mean)
library(datasets)
data(mtcars)
?mtcars
mtcars
lapply(mtcars, mean)
mean(mtcars$mpg)
sapply(mtcars, cyl, mean)
sapply(split(mtcars$mpg, mtcars$cyl, mean)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
tapply(mtcars$mpg, mtcars$cyl, mean)
mean(mtcars$mpg, mtcars$cyl)
with(mtcars, tapply(mpg, cyl, mean))
?with
?mtcars
tapply(mtcars$hp, mtcars$cyl)
tapply(mtcars$hp, mtcars$cyl, mean)
x <- tapply(mtcars$hp, mtcars$cyl, mean)
x
x$8-x$4
x$"8"-x$"4"
x[, "8"]-x[, "4"]
x[, 3]-x[, 1]
class(x)
unclass(x)
x["8"] - x["4"]
debug(ls)
ls
ls()
makeVector <- function(x = numeric()) {
m <- NULL
set <- function(y) {
x <<- y
m <<- NULL
}
get <- function() x
setmean <- function(mean) m <<- mean
getmean <- function() m
list(set = set, get = get,
setmean = setmean,
getmean = getmean)
}
cachemean <- function(x, ...) {
m <- x$getmean()
if(!is.null(m)) {
message("getting cached data")
return(m)
}
data <- x$get()
m <- mean(data, ...)
x$setmean(m)
m
}
library(datasets)
iris
iris$Sepal.Length
iris[, "Sepal.Length"]
mean(iris$Sepal.Length)
?lapply
?tapply
tapply(iris$Sepal.Length, iris$Species, mean)
?colMeans
apply(iris[, 1:4], 2, mean)
data(mtcars)
?mtcars
head (mtcars)
sapply(mtcars, cyl, mean)
sapply(split(mtcars$mpg,mtcars$cyl),mean)
split(mtcars$mpg,mtcars$cyl)
with(mtcars,tapply(mpg,cyl,mean))
with(mtcars,tapply(hp,cyl,mean))
x <- with(mtcars,tapply(hp,cyl,mean))
class(x)
x["4"]
x["4"]-x["8"]
abs(x["4"]-x["8"])
debug(ls)
ls()
library(swirl)
swirl()
ls(plants)
ls()
class(plants)
dim(plants)
nrow(plants)
ncol(plants)
object.size(plants)
names(plants)
head(plants)
head(plants, 10)
tail(plants, 15)
summary(plants)
table(plants)
table(plants$Active_Growth_Period)
str(plants)
?sample
?sample
sample(1:6, 4, replace = TRUE)
sample(1:6, 4, replace = TRUE)
sample(1:20, 10)
LETTERS
sample(letters)
sample(LETTERS)
flips <- sample(c(0,1), 100, replacement = TRUE, prob = c(0.3,0.7))
flips <- sample(c(0,1), 100, replace = TRUE, prob = c(0.3,0.7))
flips
sum(flips)
?rbinom
rbinom(1, size = 100, prob = 0.7)
play()
rbinom(2, size = 100, prob = 0.7)
rbinom(3, size = 100, prob = 0.7)
nxt()
flips2 <- rbinom(100, size = 1, prob = 0.7)
flips2
sum(flips2)
?rnorm
rnorm(10)
rnorm(10, 100, 25)
?rpois
rpois(5, 10)
my_pois <- replicate(100, rpois(5, 10))
my_pois
cm <- colMeans(my_pois)
hist(cm)
data(cars)
?cars
head(cars)
plot(cars)
?plot
plot(x = cars$speed, y = cars$dist)
plot(y = cars$speed, x = cars$dist)
plot(x = cars$speed, y = cars$dist, xlab = "Speed")
plot(x = cars$speed, y = cars$dist, xlab = "Speed", ylab = "Stopping Distance")
plot(x = cars$speed, y = cars$dist, ylab = "Stopping Distance")
plot(x = cars$speed, y = cars$dist, xlab = "Speed", ylab = "Stopping Distance")
plot(cars, main = "My Plot")
plot(cars, sub = "My Plot Subtitle")
?par
plot(cars, col=2)
play()
par(cars)
nxt()
plot(cars, xlim = c(10,15))
?points
?par
plot(cars, pch=2)
data(mtcars)
?boxplot
boxplot(mpg ~ cyl, data = mtcars)
hist(mtcars$mpg)
library(swirl  )
swirl()
select(cran, ip_id, package, country)
library(swirl)
swirl()
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
play()
?read.csv
nxt()
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
?tbl_df
tbl_df
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
-5:20
-(5:20)
select(cran, -(X:size))
filter(cran, package == "swirl")
filter(cran, r_version = "3.1.1", country =="US")
filter(cran, r_version = "3.1.1", country == "US")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "US"| country == "IN")
filter(cran, size > 100500, r_os = "linux-gnu")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3,5,NA,10))
!is.na(c(3,5,NA,10))
filter(cran, !is.na(r_version))
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id)
)
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
select(cran, ip_id, package, size)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_gb = size_mb / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size - 1000)
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
install.packages('RMySQL',type='source')
library(RMySQL)
library(RMySQL)
install.packages("DBI")
x <- c(2,3,4)
system.time(mean(x))
?system.time
source("http://bioconductor.org/biocLite.R")
biocLite("rhdf5")
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "cfcff17a0b9e136129a5",
secret = "8bb8c8b997151855abb049d8741c512319b13b53")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
content(req)
## 1) Merges the training and the test sets to create one data set.
## 2) Extracts only the measurements on the mean and standard deviation for each measurement.
## 3) Uses descriptive activity names to name the activities in the data set
## 4) Appropriately labels the data set with descriptive variable names.
## 5) From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
##Need to set working directory to the location of UCI HAR Dataset folder before running
library(dplyr)
##Read all relavant data files
setwd("UCI HAR Dataset/train")
subjtrain <- read.table("subject_train.txt", colClasses = "numeric")
xtrain <- read.table("X_train.txt", colClasses = "numeric")
ytrain <- read.table("y_train.txt", colClasses = "numeric")
setwd("..")
setwd("test")
subjtest <- read.table("subject_test.txt", colClasses = "numeric")
xtest <- read.table("X_test.txt", colClasses = "numeric")
ytest <- read.table("y_test.txt", colClasses = "numeric")
setwd("..")
actlabel <- read.table("activity_labels.txt", colClasses = "character")
features <- read.table("features.txt", colClasses = "character")
##Bind data together
alltrain <- cbind(subjtrain, ytrain, xtrain)
alltest <- cbind(subjtest, ytest, xtest)
dt <- rbind(alltrain, alltest)
colnames(dt) <- c("subject", "activity", features[, 2])
##Extract only columns with mean or std data
dtmeanstd <- dt[, c("subject", "activity", grep("mean\\(\\)|std\\(\\)", features[, 2], value = TRUE))]
##Replace activity number with activity names
for(i in 1:length(dtmeanstd$activity)) {
dtmeanstd$activity[i] <- actlabel[dtmeanstd$activity[i], 2]
}
#Create tidy data
dttidy <- dtmeanstd %>% group_by(subject, activity) %>% summarize_each(funs(mean))
##Create txt file
write.table(dttidy, file = "tidy data.txt", row.names = FALSE)
setwd("~/Coursera/Data Cleaning/Final Project")
## 1) Merges the training and the test sets to create one data set.
## 2) Extracts only the measurements on the mean and standard deviation for each measurement.
## 3) Uses descriptive activity names to name the activities in the data set
## 4) Appropriately labels the data set with descriptive variable names.
## 5) From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
##Need to set working directory to the location of UCI HAR Dataset folder before running
library(dplyr)
##Read all relavant data files
setwd("UCI HAR Dataset/train")
subjtrain <- read.table("subject_train.txt", colClasses = "numeric")
xtrain <- read.table("X_train.txt", colClasses = "numeric")
ytrain <- read.table("y_train.txt", colClasses = "numeric")
setwd("..")
setwd("test")
subjtest <- read.table("subject_test.txt", colClasses = "numeric")
xtest <- read.table("X_test.txt", colClasses = "numeric")
ytest <- read.table("y_test.txt", colClasses = "numeric")
setwd("..")
actlabel <- read.table("activity_labels.txt", colClasses = "character")
features <- read.table("features.txt", colClasses = "character")
##Bind data together
alltrain <- cbind(subjtrain, ytrain, xtrain)
alltest <- cbind(subjtest, ytest, xtest)
dt <- rbind(alltrain, alltest)
colnames(dt) <- c("subject", "activity", features[, 2])
##Extract only columns with mean or std data
dtmeanstd <- dt[, c("subject", "activity", grep("mean\\(\\)|std\\(\\)", features[, 2], value = TRUE))]
##Replace activity number with activity names
for(i in 1:length(dtmeanstd$activity)) {
dtmeanstd$activity[i] <- actlabel[dtmeanstd$activity[i], 2]
}
#Create tidy data
dttidy <- dtmeanstd %>% group_by(subject, activity) %>% summarize_each(funs(mean))
##Create txt file
write.table(dttidy, file = "tidy data.txt", row.names = FALSE)
head(dttidy)
